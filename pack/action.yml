name: 'pack'
description: 'Packakge RC for this service'
outputs:
  service-name:
    description: "Service Name"
    value: ${{ steps.packer.outputs.service_name }}
  target-env:
    description: "Target environment"
    value: ${{ steps.packer.outputs.target_env }}
  s3-prefix:
    description: "S3 key prefix where the RC was uploaded"
    value: ${{ steps.packer.outputs.s3_prefix }}
  s3-bucket:
    description: "S3 bucket to where the RC was uploaded"
    value: ${{ steps.packer.outputs.s3_bucket }}
  rc-version:
    description: "RC version"
    value: ${{ steps.packer.outputs.rc_version }}
runs:
  using: "composite"
  steps:
    - run: |
          # Login to Code Artifact and configure pip to use it as an extra pypi
          APP_CA_DOMAIN=agwafarm-private
          APP_CA_REPOSITORY=agwafarm-private
          APP_CA_DOMAIN_OWNER_ACCOUNT=953022346399
          APP_CA_REGION=us-west-2
          CODEARTIFACT_AUTH_TOKEN=$(aws codeartifact get-authorization-token --domain $APP_CA_DOMAIN --domain-owner $APP_CA_DOMAIN_OWNER_ACCOUNT --query authorizationToken --output text)
          aws codeartifact login --tool twine --repository $APP_CA_REPOSITORY --domain $APP_CA_DOMAIN --domain-owner $APP_CA_DOMAIN_OWNER_ACCOUNT
          pip config set global.extra-index-url https://aws:$CODEARTIFACT_AUTH_TOKEN@$APP_CA_DOMAIN-$APP_CA_DOMAIN_OWNER_ACCOUNT.d.codeartifact.$APP_CA_REGION.amazonaws.com/pypi/$APP_CA_REPOSITORY/simple/

          # Compute useful variables and outputs
          service_name=$(echo $GITHUB_REPOSITORY | sed -e 's/^agwafarm\///')
          service_name=$(echo $service_name | sed -e 's/^agwa\-//')
          service_name=$(echo $service_name | sed -e 's/^\-service//')
          export SERVICE_NAME=$service_name
          echo packaging service $service_name
          echo "::set-output name=service_name::$SERVICE_NAME"

          rc_version=$GITHUB_SHA
          echo RC version $rc_version
          echo ::set-output name=rc_version::$rc_version

          event_name=$GITHUB_EVENT_NAME
          echo github event name $event_name

          if [ "$event_name" = "pull_request" ]; then
             git_ref=$GITHUB_HEAD_REF
          else
             git_ref=$GITHUB_REF
          fi
          echo git ref $git_ref

          branch_name=$(echo $git_ref | sed -e 's/^refs\/heads\///')
          echo branch name $branch_name

          if [ "$branch_name" = "main" ] || [ "$branch_name" = "master" ]; then
             target_env=test
             export AGWA_SERVICE_LIBRARY_TAG=latest
          else
             user_name=$(echo $GITHUB_ACTOR | sed -e 's/[^[:alnum:]]+/_/g')
             user_name=$(echo $user_name | sed -e 's/\(.*\)/\L\1/')
             echo user name $user_name 
             
             #  TODO add -$user_name
             export AGWA_SERVICE_LIBRARY_TAG=edge
             
             #  TODO add -$user_name
             target_env=dev
          fi

          echo target env $target_env
          echo ::set-output name=target_env::$target_env
          
          s3_bucket=agwa-ci-assets
          echo ::set-output name=s3_bucket::$s3_bucket

          s3_prefix=$target_env/$service_name/$rc_version
          echo ::set-output name=s3_prefix::$s3_prefix
          
          s3_path_base=s3://$s3_bucket/$s3_prefix
          echo s3 path base $s3_path_base

          current_folder=$(pwd)
          common_layer_path=artifacts/layers/common
          asset_name=asset.zip

          #Upload CloudFormation Assets
          aws s3 sync --delete src/cloudformation $s3_path_base/cloudformation
          
          # Upload Lambda & Layer Assets
          mkdir -p $common_layer_path
          python3 -m pip install -q -r requirements.txt --target $common_layer_path/python
          cd $common_layer_path
          zip -q -r $asset_name .
          aws s3 cp $asset_name $s3_path_base/layers/cloud-common.zip
          cd $current_folder

          for d in src/lambdas/*/ ; do
            func_name=$(basename "$"$d"")
            func_path=src/lambdas/${func_name}
            func_artifact_folder=artifacts/lambdas/${func_name}
            func_s3_key=$s3_path_base/functions/${func_name}.zip
            req_path=src/lambdas/${func_name}/requirements.txt
            layer_path=artifacts/layers/lambdas/${func_name}
            layer_s3_key=$s3_path_base/layers/${func_name}.zip
            
            cd $current_folder
            mkdir -p $func_artifact_folder
            if [ -f $req_path ]; then
              mkdir -p $layer_path
              python3 -m pip install -q -r $req_path --target $layer_path/python
              cd $layer_path
              zip -q -r $asset_name .
              aws s3 cp $asset_name $layer_s3_key
              cd $current_folder
            fi
            
            cd $func_path
            zip -q -r $asset_name .
            aws s3 cp $asset_name $func_s3_key
            cd $current_folder
          done

      shell: bash
      id: packer